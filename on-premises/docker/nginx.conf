# ==============================================================================
# NGINX REVERSE PROXY CONFIGURATION
# Documentation template for Base64.ai On-Premises deployment
# ==============================================================================
#
# This configuration routes traffic to the following services:
#   - API Server (main application)
#   - MCP Server (Model Context Protocol for streaming)
#   - Integrate (n8n workflow automation)
#   - Kibana (Elasticsearch dashboard)
#
# IMPORTANT: Replace all <example_hostname> placeholders with your actual hostname
# Example: If your domain is "docai.company.com", replace:
#   - <example_hostname> → docai.company.com
#   - integrate.<example_hostname> → integrate.docai.company.com
#   - mcp.<example_hostname> → mcp.docai.company.com
#   - kibana.<example_hostname> → kibana.docai.company.com
#
# ==============================================================================

# ==============================================================================
# API SERVER - Main Application
# Handles all document processing API requests and serves the web UI
# ==============================================================================
server {
    # Port to listen on (80 for HTTP, 443 for HTTPS)
    listen 80;
    
    # Server name - the hostname users will use to access the application
    # Replace with your actual hostname (e.g., docai.company.com)
    server_name <example_hostname>;

    # Maximum allowed request body size (for document uploads)
    # Adjust based on your maximum expected document size
    client_max_body_size 100M;
    
    # Timeout for reading response from proxied server
    # Increase for large document processing operations
    proxy_read_timeout 300s;
    
    # Timeout for establishing connection to proxied server
    proxy_connect_timeout 75s;

    # Route all requests to the API service
    location / {
        # Forward requests to the API container on port 3000
        proxy_pass http://api:3000;
        
        # Use HTTP/1.1 for better connection handling
        proxy_http_version 1.1;
        
        # Preserve original host header for proper routing
        proxy_set_header Host $host;
        
        # Forward client's real IP address
        proxy_set_header X-Real-IP $remote_addr;
        
        # Forward the chain of client IPs (for load balancers)
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Forward the original protocol (http/https)
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Disable connection keep-alive header forwarding
        proxy_set_header Connection "";

        # Buffer settings for large responses
        # Increase these if you experience issues with large API responses
        proxy_buffer_size          128k;
        proxy_buffers              4 256k;
        proxy_busy_buffers_size    256k;
    }
}

# ==============================================================================
# MCP SERVER - Model Context Protocol (Streaming Endpoint)
# Handles streaming responses for LLM/AI features
# Optimized for Server-Sent Events (SSE) and streaming
# ==============================================================================
server {
    listen 80;
    
    # MCP subdomain for streaming API requests
    # Replace with your actual hostname (e.g., mcp.docai.company.com)
    server_name mcp.<example_hostname>;

    client_max_body_size 100M;
    proxy_read_timeout 300s;
    proxy_connect_timeout 75s;

    location / {
        # Forward requests to the API container on port 3001 (MCP port)
        proxy_pass http://api:3001;

        # === STREAMING CONFIGURATION ===
        # These settings are critical for SSE/streaming to work properly
        
        proxy_http_version 1.1;
        
        # Disable connection header for streaming
        proxy_set_header Connection "";
        
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # === DISABLE BUFFERING FOR STREAMING ===
        # Critical: Buffering must be disabled for real-time streaming
        proxy_buffering off;
        
        # Disable caching for streaming responses
        proxy_cache off;
        
        # Tell upstream servers not to buffer
        proxy_set_header X-Accel-Buffering no;

        # Smaller buffer sizes for streaming (reduces latency)
        proxy_buffer_size 32k;
        proxy_buffers 8 32k;
        proxy_busy_buffers_size 64k;

        # Enable chunked transfer encoding for streaming
        chunked_transfer_encoding on;
        
        # Disable Nagle's algorithm for lower latency
        tcp_nodelay on;
    }
}

# ==============================================================================
# INTEGRATE SERVER - n8n Workflow Automation
# Provides workflow automation and webhook capabilities
# Supports WebSocket connections for real-time updates
# ==============================================================================
server {
    listen 80;
    
    # Integrate subdomain for n8n workflow automation
    # Replace with your actual hostname (e.g., integrate.docai.company.com)
    server_name integrate.<example_hostname>;

    client_max_body_size 100M;
    proxy_read_timeout 300s;
    proxy_connect_timeout 75s;

    location / {
        # Forward requests to the integrate (n8n) container on port 5678
        proxy_pass http://integrate:5678;
        
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        
        # === WEBSOCKET SUPPORT ===
        # Required for n8n's real-time features and editor
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Buffer settings for workflow responses
        proxy_buffer_size          128k;
        proxy_buffers              4 256k;
        proxy_busy_buffers_size    256k;
    }
}

# ==============================================================================
# KIBANA SERVER - Elasticsearch Dashboard
# Provides visualization and management interface for Elasticsearch
# ==============================================================================
server {
    listen 80;
    
    # Kibana subdomain for Elasticsearch dashboard
    # Replace with your actual hostname (e.g., kibana.docai.company.com)
    server_name kibana.<example_hostname>;

    client_max_body_size 100M;
    proxy_read_timeout 300s;
    proxy_connect_timeout 75s;

    location / {
        # Forward requests to the Kibana container on port 5601
        proxy_pass http://kibana:5601;
        
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        
        # WebSocket support for Kibana's real-time features
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Buffer settings
        proxy_buffer_size          128k;
        proxy_buffers              4 256k;
        proxy_busy_buffers_size    256k;
    }
}

# ==============================================================================
# OPTIONAL: LDAP SERVER (Uncomment if using LDAP authentication)
# Provides LDAP proxy for directory services authentication
# ==============================================================================
# server {
#     listen 80;
#     
#     # LDAP subdomain (e.g., ldap.docai.company.com)
#     server_name ldap.<example_hostname>;
#
#     client_max_body_size 100M;
#     proxy_read_timeout 300s;
#     proxy_connect_timeout 75s;
#
#     location / {
#         # Forward to OpenLDAP container
#         # Port 1389 for non-TLS, Port 1636 for TLS
#         proxy_pass http://openldap:1389;
#         
#         proxy_http_version 1.1;
#         proxy_set_header Host $host;
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-Forwarded-Proto $scheme;
#     }
# }

# ==============================================================================
# HTTPS CONFIGURATION TEMPLATE (Uncomment and configure for SSL/TLS)
# Replace the HTTP server blocks above with these for production use
# ==============================================================================
#
# server {
#     listen 443 ssl http2;
#     server_name <example_hostname>;
#
#     # SSL Certificate paths
#     ssl_certificate     /etc/nginx/ssl/certificate.crt;
#     ssl_certificate_key /etc/nginx/ssl/certificate.key;
#
#     # SSL Configuration (modern settings)
#     ssl_protocols TLSv1.2 TLSv1.3;
#     ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
#     ssl_prefer_server_ciphers off;
#
#     # HSTS (uncomment for production)
#     # add_header Strict-Transport-Security "max-age=63072000" always;
#
#     client_max_body_size 100M;
#     proxy_read_timeout 300s;
#     proxy_connect_timeout 75s;
#
#     location / {
#         proxy_pass http://api:3000;
#         proxy_http_version 1.1;
#         proxy_set_header Host $host;
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-Forwarded-Proto $scheme;
#         proxy_set_header Connection "";
#
#         proxy_buffer_size          128k;
#         proxy_buffers              4 256k;
#         proxy_busy_buffers_size    256k;
#     }
# }
#
# # HTTP to HTTPS redirect
# server {
#     listen 80;
#     server_name <example_hostname>;
#     return 301 https://$server_name$request_uri;
# }

# ==============================================================================
# CONFIGURATION REFERENCE
# ==============================================================================
#
# HOSTNAMES SUMMARY:
# ┌─────────────────────────────────┬─────────────────────────────────────────┐
# │ Subdomain                       │ Purpose                                 │
# ├─────────────────────────────────┼─────────────────────────────────────────┤
# │ <example_hostname>              │ Main application and API                │
# │ mcp.<example_hostname>          │ Model Context Protocol (LLM streaming)  │
# │ integrate.<example_hostname>    │ n8n workflow automation                 │
# │ kibana.<example_hostname>       │ Elasticsearch dashboard                 │
# └─────────────────────────────────┴─────────────────────────────────────────┘
#
# INTERNAL SERVICE PORTS:
# ┌─────────────────┬────────┬────────────────────────────────────────────────┐
# │ Service         │ Port   │ Description                                    │
# ├─────────────────┼────────┼────────────────────────────────────────────────┤
# │ api             │ 3000   │ Main API server (UI and REST API)              │
# │ api             │ 3001   │ MCP server (streaming endpoint)                │
# │ integrate       │ 5678   │ n8n workflow server                            │
# │ kibana          │ 5601   │ Kibana web interface                           │
# │ elasticsearch   │ 9200   │ Elasticsearch REST API (internal only)         │
# └─────────────────┴────────┴────────────────────────────────────────────────┘
#
# DNS REQUIREMENTS:
# Configure your DNS to point all subdomains to this nginx server's IP:
#   - <example_hostname>           → <nginx_server_ip>
#   - mcp.<example_hostname>       → <nginx_server_ip>
#   - integrate.<example_hostname> → <nginx_server_ip>
#   - kibana.<example_hostname>    → <nginx_server_ip>
#
# Or use a wildcard DNS record:
#   - *.<example_hostname>         → <nginx_server_ip>
#
# ==============================================================================
